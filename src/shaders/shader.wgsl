struct Camera {
    pos: vec3<f32>,
    rot_transform: mat3x3<f32>,
    /// The vertical fov, in radians.
    fov_y: f32,
}

struct Ray {
    origin: vec3<f32>,
    /// Must be normalized.
    direction: vec3<f32>,
}

struct HitInfo {
    did_hit: bool,
    distance: f32,
    hit_point: vec3<f32>,
    normal: vec3<f32>,
    material_id: u32,
}

const NO_HIT = HitInfo(
    false,
    0.0,
    vec3<f32>(0.0),
    vec3<f32>(0.0),
    0u,
);

struct BsdfSample {
    /// The reflected camera view direction. If this is the zero vector, some
    /// error occurred while this sample was calculated.
    ray_direction: vec3<f32>,
    light: vec3<f32>,
    /// I assume that this is the probability density that the `wi_world`
    /// would've been chosen.
    pdf: f32,
}

/// Represents a local coordinate space with the normal of a surface point
/// being the forward direction (z+).
struct Frame {
    tangent: vec3<f32>,
    bitangent: vec3<f32>,
    normal: vec3<f32>,
}

fn make_frame(normal: vec3<f32>) -> Frame {    
    // Pick a helper axis that is not parallel to normal.
    let helper = select(
        vec3<f32>(1,0,0),
        vec3<f32>(0,0,1),
        abs(normal.z) < 0.999
    );
    
    let tangent = normalize(cross(helper, normal));
    let bitangent = cross(normal, tangent);
    
    return Frame(tangent, bitangent, normal);
}

fn to_frame_local(frame: Frame, vec_world: vec3<f32>) -> vec3<f32> {
    // Return the components in the basis.
    return vec3<f32>(
        dot(vec_world, frame.tangent),
        dot(vec_world, frame.bitangent),
        dot(vec_world, frame.normal),
    );
}

fn to_frame_world(frame: Frame, vec_local: vec3<f32>) -> vec3<f32> {
    return normalize(
        frame.tangent * vec_local.x
        + frame.bitangent * vec_local.y
        + frame.normal * vec_local.z
    );
}

struct Material {
    color: vec3<f32>,
    roughness: f32,
    metallic: f32,
    emission: vec3<f32>,
}

struct Sphere {
    pos: vec3<f32>,
    radius: f32,
    material_id: u32,
}

struct Plane {
    pos: vec3<f32>,
    normal: vec3<f32>,
    /// Let
    /// - plane be the original plane
    /// - normal = plane.forward × plane.right
    /// - B be the base {plane.right, normal, plane.forward}
    ///
    /// The this is the change-of-basis matrix which converts between the standard base and B.
    base_change_matrix: mat3x3<f32>,
    material_id: u32,
}

@group(0) @binding(0)
var out_texture: texture_storage_2d<rgba16float, write>;

@group(1) @binding(0)
var<uniform> camera: Camera;

@group(1) @binding(1)
var<uniform> resolution: vec2<u32>;

@group(1) @binding(2)
var<uniform> time_secs: f32;

@group(2) @binding(0)
var<storage, read> materials: array<Material>;

@group(2) @binding(1)
var<storage, read> spheres: array<Sphere>;

@group(2) @binding(2)
var<storage, read> planes: array<Plane>;

const NUM_SAMPLES: u32 = 50;
const MAX_BOUNCES: u32 = 10;

// Largest representable f32 (actual IEEE infinity can't be used).
const INFINITY = 1.70141183460469231732e+38f;
// Smallest representable f32 (actual IEEE negative infinity can't be used).
const NEG_INFINITY = -1.70141183460469231732e+38f;

const PI = 3.14159;

fn lerp_vec3f(a: vec3<f32>, b: vec3<f32>, t: f32) -> vec3<f32> {
    return (1.0 - t) * a + t * b;
}

fn lerp_f32(a: f32, b: f32, t: f32) -> f32 {
    return (1.0 - t) * a + t * b;
}

/// Returns value equivalent to `length(v) * length(v)`.
fn length_squared(v: vec3<f32>) -> f32 {
    return dot(v, v);
}

/// Returns the largest component of `v`.
fn max_component(v: vec3<f32>) -> f32 {
    return max(v.x, max(v.y, v.z));
}

// Random number generator

// Returns a random float in the range [0,1), updating the RNG state in the
// process.
fn random_uniform(rng_state: ptr<function, u32>) -> f32 {
    *rng_state = *rng_state * 747796405 + 2891336453;
    var result = ((*rng_state >> ((*rng_state >> 28) + 4)) ^ *rng_state)
        * 277803737;
    result = (result >> 22) ^ result;
    return f32(result) / 4294967295.0;
}

// Returns a uniformly distributed random point on the unit circle. The point's
// length is in the range [0,1).
fn random_in_circle_uniform(rng_state: ptr<function, u32>) -> vec2<f32> {
    let angle: f32 = random_uniform(rng_state) * 2 * 3.1415926;
    let pointOnCircle = vec2(cos(angle), sin(angle));
    return pointOnCircle * sqrt(random_uniform(rng_state));
}

// Returns a uniformly distributed random point on the unit sphere. The point's
// length is in the range [0,1).
// 
// Algorithm generated by ChatGPT. :)
// 
// Apparently the distribution is uniform if longitude and cos(latitude) are
// uniformly distributed.
fn random_in_sphere_uniform(rng_state: ptr<function, u32>) -> vec3<f32> {
    let u = random_uniform(rng_state);
    let v = random_uniform(rng_state);
    
    let longitude = 2. * PI * u;
    // This is equal to cos(latitude).
    let z = 2. * v - 1.;
    
    let r = sqrt(1. - z * z);
    
    let x = r * cos(longitude);
    let y = r * sin(longitude);
    
    return vec3(x, y, z);
}

// Returns a uniformly distributed random point on the unit sphere's hemisphere
// defined by the given normal. The point's length is in the range [0,1).
fn random_in_hemisphere_uniform(normal: vec3<f32>, rng_state: ptr<function, u32>) -> vec3<f32> {
    let point = random_in_sphere_uniform(rng_state);
    return point * sign(dot(normal, point));
}

fn sky_color(ray_direction: vec3<f32>) -> vec3<f32> {
    let t = 0.5 * (ray_direction.y + 1.0);
    return select(
        lerp_vec3f(vec3(1.0, 1.0, 1.0), vec3(0.5, 0.7, 1.0), t),
        vec3(0.16, 0.16, 0.16),
        ray_direction.y < 0.,
    );
}

fn cast_ray_sphere(ray: Ray, sphere: Sphere) -> HitInfo {
    const EPSILON = 0.0001;
    
    let l = ray.origin - sphere.pos;
    let a = dot(ray.direction, ray.direction);
    let b = 2 * dot(ray.direction, l);
    let c = dot(l, l) - sphere.radius * sphere.radius;
    
    // Solve at^2 + bt + c = 0
    var t: f32;
    let discriminant = b * b - 4 * a * c;
    if discriminant < 0 {
        return NO_HIT;
    } else if discriminant == 0 {
        t = -0.5 * b / a;
    } else {
        let q = select(
            -0.5 * (b - sqrt(discriminant)),
            -0.5 * (b + sqrt(discriminant)),
            b > 0,
        );
        let t_0 = q / a;
        let t_1 = c / q;
        
        // We ignore collisions from rays that start very close to the surface
        // to address shadow acne.
        
        if t_0 < EPSILON {
            t = t_1;
        } else if t_1 < EPSILON {
            t = t_0;
        } else {
            t = min(t_0, t_1);
        }
    }
    
    if t < EPSILON {
        return NO_HIT;
    }

    let hit_point = ray.origin + ray.direction * t;
    
    var normal = normalize(hit_point - sphere.pos);
    
    // We consider origins that are slightly outside the sphere as within it to
    // correctly reflect rays bouncing in sphere interior.
    // TODO: This causes strange acne-like noise occurring when the camera is
    //   relatively far away from the surface, presumably because some of the
    //   reflected rays end up intersecting with the same surface, and are then
    //   considered as having originated inside the sphere, being reflected into
    //   it.
    if length_squared(sphere.pos - ray.origin) - sphere.radius * sphere.radius
        < EPSILON
    {
        // Ray originates within sphere, flip normal.
        normal *= -1.;
    }
    
    return HitInfo(
        true,
        t,
        hit_point,
        normal,
        sphere.material_id,
    );
}

fn cast_ray_plane(ray: Ray, plane: Plane) -> HitInfo {
    let denominator = dot(plane.normal, ray.direction);
    if (abs(denominator) < 0.0001) {
        // The ray is parallel to the plane
        return NO_HIT;
    }
    let t = dot(plane.normal, plane.pos - ray.origin) / denominator;
    // Ignore collisions that are very close to surface. This addresses shadow
    // acne.
    if (t < 0.001) {
        // Intersection point is behind ray
        return NO_HIT;
    }
    
    // Point on plane the ray would intersect with if the plane extended
    // infinitely
    let inter = ray.origin + ray.direction * t;
        
    // `inter`, but relative to the plane's position.
    let inter_local = inter - plane.pos;
    // The point in the "plane's base".
    let inter_plane_space = plane.base_change_matrix * inter_local;
    
    if inter_plane_space.x < 0.
        || 1. < inter_plane_space.x
        || inter_plane_space.z < 0.
        || 1. < inter_plane_space.z
    {
        return NO_HIT;
    }
    
    var normal = plane.normal;
    if dot(ray.origin, normal) < 0. {
        // Ray originates below plane, flip normal.
        normal *= -1;
    }
    
    return HitInfo(
        true,
        t,
        inter,
        normal,
        plane.material_id,
    );
}

// Cast ray through scene, returning the surface if one was hit.
fn cast_ray(ray: Ray) -> HitInfo {
    var result = HitInfo(
        false,
        INFINITY,
        vec3<f32>(0.0),
        vec3<f32>(0.0),
        0u,
    );
    
    for (var i: u32 = 0; i < arrayLength(&spheres); i++) {
        let sphere = spheres[i];
        
        let info = cast_ray_sphere(ray, sphere);
        if info.did_hit && info.distance < result.distance {
            result = info;
        }
    }
    for (var i: u32 = 0; i < arrayLength(&planes); i++) {
        let plane = planes[i];
        
        let info = cast_ray_plane(ray, plane);
        if info.did_hit && info.distance < result.distance {
            result = info;
        }
    }
    
    return result;
}

/// The parameters representing a surface material required for a BSDF shader.
struct BsdfMaterial {
    // The albedo for diffuse materials, and metal reflectance for metals.
    color: vec3<f32>,
    metallic: f32,
    /// Surface variance parameter. This somehow represents the surface
    /// microfacet normal distribution. The distribution describes the
    /// percentage of microfacets with a certain normal for a given surface
    /// point.
    alpha: f32,
    /// The fresnel reflectance at normal incidence, i.e. the fraction of light
    /// that is reflected when a ray of light hits the surface head-on.
    f0: vec3<f32>,
}

fn make_bsdf_material(material: Material) -> BsdfMaterial {
    // TODO: Support perfectly smooth materials using separate shader.
    let alpha = max(0.001, material.roughness * material.roughness);
    return BsdfMaterial(
        material.color,
        material.metallic,
        alpha,
        surface_f0(material),
    );
}

/// The fresnel reflectance at normal incidence of a dielectric surface (a
/// non-metal). Read non-conductive.
const DIELECTRIC_F0 = vec3<f32>(0.04, 0.04, 0.04);

/// Computes fresnel reflectance at normal incidence for the given material,
/// i.e. the fraction of light that is reflected when a ray of light hits the
/// surface head-on.
fn surface_f0(material: Material) -> vec3<f32> {
    // F0 is equal to the base color for metallic matterials and `DIELECTRIC_F0` for
    // diffuse materials.
    return lerp_vec3f(DIELECTRIC_F0, material.color, saturate(material.metallic));
}

/// Computes the diffuse reflectance coefficient for the given material, i.e.
/// the fraction of incoming light that enters the surface, scatters internally,
/// and then exits back out diffusely.
fn surface_kd(material: BsdfMaterial) -> vec3<f32> {
    let kd0 = material.color * (1 - saturate(material.metallic));
    return kd0 * (1 - max_component(material.f0));
}

/// Computes the "luminance" of a color.
fn luminance(color: vec3<f32>) -> f32 {
    return 0.2126 * color.r + 0.7152 * color.g + 0.0722 * color.b;
}

/// Returns the point of the hemisphere pointed towards +z, corresponding to the
/// given pair of coordinates. These should be in the range [0,1). If the
/// coordinates have been selected by a uniform distribution the point in the
/// hemisphere has a "cosine-weighted distribution".
fn sample_cosine_hemisphere(sample: vec2<f32>) -> vec3<f32> {
    let r = sqrt(sample.x);
    let phi = 2 * PI * sample.y;

    let x = r * cos(phi);
    let y = r * sin(phi);
    let z = sqrt(max(0., 1. - x * x - y * y));

    return vec3(x, y, z);
}

/// Returns the point on the unit disk corresponding to the given pair of
/// coordinates. These should be in the range [0,1). If the coordinates have
/// been selected by a uniform distribution the points in the disk will also
/// have a uniform distribution.
fn sample_uniform_disk(sample: vec2<f32>) -> vec2<f32> {
    let radius = sqrt(sample.x);
    let azimuth = 2 * PI * sample.y;
    return vec2<f32>(radius * cos(azimuth), radius * sin(azimuth));
}

/// Returns the PDF value of a direction in frame local space or something.
fn pdf_cosine_hemisphere(wi: vec3<f32>) -> f32 {
    if wi.z <= 0 {
        return 0.;
    }
    return wi.z / PI;
}

/// Calculates the microfacet orientation density of the given microfacet normal
/// h for a material with the given surface variance `alpha`. If n is the
/// surface normal, then the argument `normal_dot_h` should be equal to dot(n,h).
fn d_ggx(normal_dot_h: f32, alpha: f32) -> f32 {
    let alpha_2 = alpha * alpha;
    let denominator = (normal_dot_h * normal_dot_h) * (alpha_2 - 1.) + 1.;
    return alpha_2 / (PI * denominator * denominator);
}

/// Returns the value of `sample_ggx_visible_half_vector`'s PDF.
fn pdf_ggx_half_vector_visible(h: vec3<f32>, wo: vec3<f32>, alpha: f32) -> f32 {    
    // Remember, normal = vec3(0, 0, 1) in the view space (which `h` and `wo`
    // are in).
    let normal_dot_h = h.z;
    let normal_dot_wo = wo.z;
    
    if normal_dot_h <= 0. {
      return 0.;
    }
    
    return d_ggx(normal_dot_h, alpha)
        * g1_ggx(normal_dot_wo, alpha)
        * max(0., dot(wo, h))
        / normal_dot_wo;
}

/// Computes the GGX half-vector direction vector for the given pair of
/// coordinates. These should be in the range [0,1).
/// `alpha` is the surface variance parameter, i.e. the "roughness" of the
/// surface.
/// This makes sure to only return half-vectors that are visible from the given
/// out ray direction `wo`. I.e. it implements VNDF sampling.
/// Here is an example of a half-vector h that wouldn't be returned, since the
/// surface would cover it from wo.
///             /\ surface normal
///             |       __
///             |    _,-´| wo
///    h __     |_,-´
///     |`-_   /---------
///         `-/ <-- microfacet surface
///   _______/
fn sample_ggx_visible_half_vector(
    sample: vec2<f32>,
    wo: vec3<f32>,
    alpha: f32,
) -> vec3<f32> {
    // Stretch the outgoing direction. For isotropic GGX we stretch it by alpha.
    // TODO: Support anisotropy by stretching x and y differently.
    let view_stretched =
        normalize(wo * vec3(alpha, alpha, 1.));

    // The papers code
    // Build frame around the stretched view direction.
    let length_squared = dot(view_stretched.xy, view_stretched.xy);
    let tangent_x = select(
        vec3(1., 0., 0.),
        vec3(-view_stretched.y, view_stretched.x, 0.) * inverseSqrt(length_squared),
        length_squared > 0.,
    );
    let tangent_y = cross(view_stretched, tangent_x);
    
    var disk_point = sample_uniform_disk(sample);
    // Warp the disk sample so it matches the "visible normals" distribution.
    // Interpolate between "a circle and a line segment" depending on the
    // grazing angle.
    // This corresponds to constructing (t_1, t_2') in figure 6 from this
    // paper: http://jcgt.org/published/0007/04/01/.
    disk_point.y = lerp_f32(
        sqrt(max(0., 1. - disk_point.x * disk_point.x)),
        disk_point.y,
        view_stretched.z,
    );
    
    // Construct the sampled normal in the view frame's local space, i.e. the
    // space which `wo` is in (world space from the stretch frame's
    // perspective).
    let half_vector_stretched = disk_point.x * tangent_x
        + disk_point.y * tangent_y
        + sqrt(max(0., 1. - disk_point.x * disk_point.x - disk_point.y * disk_point.y)) * view_stretched;
    
    // Unstretch back into original local shading space.
    let half_vector = normalize(vec3<f32>(
        alpha * half_vector_stretched.x,
        alpha * half_vector_stretched.y,
        max(0., half_vector_stretched.z)
    ));
    
    return half_vector;
}

/// Computes the average self-occlusion along a direction v for a material with
/// the given surface variance `alpha`. If n is the surface normal, then the
/// argument `normal_dot_v` should be equal to dot(n,v).
fn lambda_ggx(normal_dot_v: f32, alpha: f32) -> f32 {
    let normal_dot_v_2 = normal_dot_v * normal_dot_v;
    
    return (sqrt(1 + alpha * alpha * (1 - normal_dot_v_2) / normal_dot_v_2)
        - 1)
        / 2;
}

/// I don't understand this, but according to ChatGPT, this calculates the
/// "single-direction visibility probability" from direction v, for a material
/// with the given surface variance `alpha`. If n is the surface normal, then
/// the argument `normal_dot_v` should be equal to dot(n,v).
fn g1_ggx(normal_dot_v: f32, alpha: f32) -> f32 {
    return 1. / (1 + lambda_ggx(normal_dot_v, alpha));
}

/// Calculates the probability that a microfacet is visible from both the viewer
/// direction o and light direction i, given a material with the surface
/// variance `alpha`.
///
/// If n is the surface normal, then the argument `normal_dot_o` and
/// `normal_dot_i` should be equal to dot(n,o) and dot(n,i) respectively.
fn g_smith_ggx(normal_dot_o: f32, normal_dot_i: f32, alpha: f32) -> f32 {
    return g1_ggx(normal_dot_o, alpha) * g1_ggx(normal_dot_i, alpha);
}

/// I also don't understand this. According to ChatGPT, this should calculate
/// the "angle-dependent surface reflectivity".
///
/// It answers the question "Given that light hits a microfacet at this angle,
/// how much of it is reflected instead of entering the material?"
fn f_schlick(f0: vec3<f32>, cos_theta: f32) -> vec3<f32> {
    let x = (1 - saturate(cos_theta));
    let x_2 = x * x;
    let x_5 = x_2 * x_2 * x;
    
    return f0 + (vec3(1.) - f0) * x_5;
}

fn bsdf_eval_local(
    wo: vec3<f32>,
    wi: vec3<f32>,
    material: BsdfMaterial
) -> vec3<f32> {
    if wo.z <= 0 || wi.z <= 0 {
        return vec3(0.,0.,0.);
    }
    
    /// The dot product of the surface normal and the respective light direction
    /// vectors.
    let normal_dot_wo = wo.z;
    let normal_dot_wi = wi.z;
    
    // The half-vector (whatever that is...)
    let h = normalize(wo + wi);
    let normal_dot_h = saturate(h.z);
    
    // Specular microfacet
    let orientation_density = d_ggx(normal_dot_h, material.alpha);
    let visibility_probability = g_smith_ggx(normal_dot_wo, normal_dot_wi, material.alpha);
    let surface_reflectivity = f_schlick(material.f0, dot(h, wo));
    
    // No clue what this is. Apparently described by "spectrum".
    let fs = (orientation_density * visibility_probability)
        / (4 * normal_dot_wo * normal_dot_wi)
        * surface_reflectivity;
    
    
    // Somehow described by "diffuse lambert":
    let kd = surface_kd(material);
    let fd = kd * (1 / PI);
    
    return fd + fs;
}

fn pdf_specular_wi_visible(wo: vec3<f32>, wi: vec3<f32>, alpha: f32) -> f32 {
    if wo.z <= 0. || wi.z <= 0. {
        return 0.;
    }
    
    let h = normalize(wo + wi);
    
    let wo_dot_h = abs(dot(wo, h));
    if wo_dot_h <= 0. {
        return 0.;
    }
    
    return pdf_ggx_half_vector_visible(h, wo, alpha) / (4 * wo_dot_h);
}

fn bsdf_pdf_local(wo: vec3<f32>, wi: vec3<f32>, material: BsdfMaterial) -> f32 {
    if wo.z <= 0. || wi.z <= 0. {
        return 0.;
    }
    
    let specular_probability = saturate(luminance(material.f0));
    let diffuse_probability = 1. - specular_probability;
    
    return diffuse_probability * pdf_cosine_hemisphere(wi)
        + specular_probability * pdf_specular_wi_visible(wo, wi, material.alpha);
}

fn bsdf_sample(
    ray: Ray,
    surface_normal: vec3<f32>,
    material_in: Material,
    rng_state: ptr<function, u32>,
) -> BsdfSample {
    let material = make_bsdf_material(material_in);
    
    // Points from the surface point to the camera (i.e. previous surface).
    let wo_world = -ray.direction;
    
    if dot(surface_normal, wo_world) <= 0 {
        return BsdfSample(
            vec3(0., 0., 0.),
            vec3(0., 0., 1.),
            0.
        );
    }
    
    let frame = make_frame(surface_normal);
    
    let wo = to_frame_local(frame, wo_world);
    
    if wo.z <= 0 {
        // wo points below the surface (can happen with shading normals), bail.
        return BsdfSample(
            vec3(0., 0., 0.),
            vec3(0., 1., 0.),
            0.
        );
    }
    
    // I think these names are correct.
    let specular_probability = saturate(luminance(material.f0));
    let diffuse_probability = 1. - specular_probability;
    
    // Choose lobe to sample.
    var wi: vec3<f32>;
    let sample = random_uniform(rng_state);
    if sample < diffuse_probability {
        // Sample diffuse.
        // For some reason we reuse the previous sample.
        wi = sample_cosine_hemisphere(vec2(
            sample / max(diffuse_probability, 1.e-6),
            random_uniform(rng_state),
        ));
    } else {
        // Sample specular.
        let h = sample_ggx_visible_half_vector(
            vec2(
                (sample - diffuse_probability)
                    / max(specular_probability, 1.e-6),
                random_uniform(rng_state),
            ),
            wo,
            material.alpha,
        );
        
        // Reflect wo about h to get wi (still in the frame's local space).
        // This convention assumes wo and wi are both above surface.
        // Note: it's critical that both `wo` and `h` are normalized.
        wi = reflect(-wo, h);
        if wi.z <= 0. {
            // `-wo` is blocked from "seeing" `h`'s surface, which the sampling
            // function should prevent (see the diagram in
            // sample_ggx_visible_half_vector).
            // This can still occur due to imprecision though.
            return BsdfSample(
                vec3(1., 0., 0.),
                vec3(1., 0., 0.),
                0.
            );
        }
    }
    
    let light = bsdf_eval_local(wo, wi, material);
    let pdf = bsdf_pdf_local(wo, wi, material);
    let wi_world = to_frame_world(frame, wi);
    
    if dot(surface_normal, wi_world) < 0 {
        return BsdfSample(
            vec3(0., 0., 0.),
            vec3(0., 1., 0.),
            0.
        );
    }
    
    return BsdfSample(wi_world, light, pdf);
}

// Trace ray through scene, returning the collected light.
fn trace_ray(ray_arg: Ray, rng_state: ptr<function, u32>) -> vec3<f32> {
    var ray = ray_arg;
    
    var incoming_light = vec3<f32>(0.);
    var throughput = vec3<f32>(1.);
    
    for (var bounce_count = 0u; bounce_count < MAX_BOUNCES; bounce_count++) {
        var info = cast_ray(ray);
        if info.did_hit {
            let material = materials[info.material_id];
            
            let sample = bsdf_sample(ray, info.normal, material, rng_state);
            if all(sample.ray_direction == vec3<f32>(0.)) {
                // Error occurred during sample calculation, show light as debug
                // information.
                incoming_light = sample.light;
                break;
            }
            if sample.pdf <= 0. {
                // Ray probability density is zero, terminate ray path.
                break;
            }
            
            // We update throughput using
            // throughput *= light * cos(theta) / pdf
            //   where cos(theta) = normal·wi in WORLD space,
            //                      using shading normal.
            let cos_theta = max(0., dot(info.normal, sample.ray_direction));
            throughput *= sample.light * (cos_theta / sample.pdf);
            incoming_light += material.emission * throughput;
            
            if (length(throughput) < 0.001) {
                // Ray contribution is negligible, terminate.
                break;
            }
            
            ray = Ray(
                info.hit_point,
                sample.ray_direction,
            );
        } else {
            incoming_light += sky_color(ray.direction) * throughput;
            break;
        }
    }
    
    return incoming_light;
}

@compute @workgroup_size(16, 16, 1)
fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {
    let pixel_coords = vec2<u32>(global_id.x, global_id.y);
    
    let pixel_index = pixel_coords.y * resolution.x + pixel_coords.x;
    var rng_state: u32 = pixel_index;
    
    var pixel_color = vec3(0.0);
    for (var i = 0u; i < NUM_SAMPLES; i++) {
        let jittered_pixel_coords =
            vec2<f32>(pixel_coords) + random_in_circle_uniform(&rng_state);
        
        // Each component is in the range -1.0 to 1.0.
        let screen_coords =
            ((jittered_pixel_coords / vec2<f32>(resolution)) * 2.0
                - vec2<f32>(1.0))
                * vec2<f32>(1.0, -1.0);
        
        // Let the b be the vertical component of ray_camera_space. For the top
        // row of pixels we want the triangle with a base of 1 and height of b
        // to have the angle opposite to b be equal to fov_y/2.
        // The definition of sin gives us this equation: sin(fov_y/2) = b / 1
        let max_y_component = sin(camera.fov_y / 2);
        
        let aspect_ratio = f32(resolution.x) / f32(resolution.y);
        
        let ray_camera_space = vec3<f32>(
            screen_coords.x * max_y_component * aspect_ratio,
            screen_coords.y * max_y_component,
            -1.0,
        );
        let ray = Ray(camera.pos, normalize(camera.rot_transform * ray_camera_space));
        
        pixel_color += trace_ray(ray, &rng_state);
    }
    pixel_color /= f32(NUM_SAMPLES);
    
    
    textureStore(out_texture, pixel_coords, vec4<f32>(pixel_color, 1.0));
}
